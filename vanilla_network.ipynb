{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sys\n",
    "from timeit import default_timer as dt\n",
    "from math import e\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def activate(x,W,b):\n",
    "    '''Defines our activation\n",
    "       function based on the \n",
    "       sigmoid activation.\n",
    "       Takes in the previous neurons\n",
    "       connected outputs x / our \n",
    "       weights W / our bias vector\n",
    "       b'''\n",
    "    return(1/(1+np.exp(-(np.dot(W,x)+b)))) #entire exponent is negative is key\n",
    "\n",
    "\n",
    "def cost(W2,W3,W4,b2,b3,b4,x1,x2,y):\n",
    "    '''Takes in our weight matrices\n",
    "       and bias vectors and computes\n",
    "       the cost function as defined \n",
    "       in the literature as our final\n",
    "       neurons values, a4 below,\n",
    "       in respect to the true output\n",
    "       squared\n",
    "       x1 - data\n",
    "       x2 - true labels\n",
    "       y - predicted points\n",
    "       Cost is run through Niter #\n",
    "       of times \n",
    "       \n",
    "    '''\n",
    "    costvector = np.zeros((10, 1))\n",
    "    x = np.zeros((2,  1))\n",
    "    for i in np.arange(costvector.shape[0]):\n",
    "        x[0,0], x[1,0] = x1[i], x2[i]\n",
    "        a2 = activate(x,  W2, b2)\n",
    "        a3 = activate(a2, W3, b3)\n",
    "        a4 = activate(a3, W4, b4)\n",
    "        costvector[i] = np.linalg.norm(a4.ravel()-y[:,i], 2)\n",
    "\n",
    "    return np.linalg.norm(costvector, 2)**2\n",
    "\n",
    "def inference(W2, W3, W4, b2, b3, b4, x_vec):\n",
    "    '''Takes in adjusted weights and \n",
    "       biases from cost function that\n",
    "       have run through our network and\n",
    "       return an output layer of \n",
    "       a^[L] = a^4 as the predicted\n",
    "       measure\n",
    "       Takes in processed weights\n",
    "       and biases and 'activates'\n",
    "       through the network using\n",
    "       input xvector data points\n",
    "       and produces a^Lth neuron \n",
    "       for our prediction\n",
    "    '''\n",
    "    a2 = activate(xvec, W2, b2)\n",
    "    a3 = activate(a2,   W3, b3)\n",
    "    a4 = activate(a3,   W4, b4)\n",
    "\n",
    "    return a4\n",
    "\n",
    "##Below section follows strictly from 'Deep learning for applied mathematicians'\n",
    "##Above functions were both shown in the paper, with cost function lifted from \n",
    "##and inference taken from final 'function y = activate(x,W,b)'\n",
    "\n",
    "\n",
    "x1 = np.array([0.1, 0.3, 0.1, 0.6, 0.4, 0.6, 0.5, 0.9, 0.4, 0.7]) #data\n",
    "x2 = np.array([0.1, 0.4, 0.5, 0.9, 0.2, 0.3, 0.6, 0.2, 0.4, 0.6]) \n",
    "\n",
    "y           = np.zeros((2, 10)) #labels (fires or does not fire) \n",
    "y[0:1, 0:5] = np.ones((1,  5))\n",
    "y[0:1, 5: ] = np.zeros((1, 5))\n",
    "y[0:1, 5: ] = np.zeros((1, 5))\n",
    "y[1: , 5: ] = np.ones((1,  5))\n",
    "\n",
    "#Normal randomization used to initialize weight matrices and biases\n",
    "W2 =  npr.uniform(size = (2,2)) #where 1st arg is the current layer size, 2nd is previous arg size\n",
    "W3 =  npr.uniform(size = (3,2)) \n",
    "W4 =  npr.uniform(size = (2,3))\n",
    "\n",
    "b2 = npr.uniform(size = (2,1))\n",
    "b3 = npr.uniform(size = (3,1))\n",
    "b4 = npr.uniform(size = (2,1))\n",
    "\n",
    "#Below is our forward and backward propogation which culminates in \n",
    "#a cost function to track our updated layers\n",
    "\n",
    "eta = .4                                # our learning rate in paper is .05, tried .4 to improve\n",
    "Niter = 100000                          #number of SG iterations\n",
    "\n",
    "savecost = np.zeros((Niter,1))           #save the value of our cost function\n",
    "\n",
    "xvec = np.zeros((2,1))\n",
    "yvec = np.zeros((2,1))\n",
    "for counter in range(Niter):\n",
    "    k = npr.randint(10)                     #choose a training node\n",
    "    xvec[0,0], xvec[1,0] = x1[k], x2[k]     #populate our input vectors\n",
    "    yvec[:,0] = y[:, k]                     #define our randomly selected node for loss purposes\n",
    "    \n",
    "    \n",
    "    #forward pass algorithm below\n",
    "    a2 = activate(xvec,W2,b2)               #first neuron has input vector of data \n",
    "    a3 = activate(a2,W3,b3)                 #second neuron uses a^1 as input data\n",
    "    a4 = activate(a3,W4,b4)\n",
    "    \n",
    "    \n",
    "    #backward pass now\n",
    "    \n",
    "    delta4 = a4*(1 - a4)*(a4-yvec)  #is this where cost comes in?         #delta, our loss term, calculated from final neuron\n",
    "                                            #along with our randomly chosen node and correct label value\n",
    "    delta3 = a3*(1 - a3)* np.dot(W4.T,delta4)  #these are defined such that they abide by\n",
    "    delta2 = a2*(1 - a2)* np.dot(W3.T,delta3)  #the loss partial derivate rules prove in section 5\n",
    "    \n",
    "    #gradient step\n",
    "    W2 -= eta*delta2*xvec.T             #update our Weights and biases using loss function, or delta\n",
    "    W3 -= eta*delta3*a2.T               #weights and biases calculated and then entered into cost function to verify decay\n",
    "    W4 -= eta*delta4*a3.T\n",
    "    b2 -= eta*delta2\n",
    "    b3 -= eta*delta3\n",
    "    b4 -= eta*delta4\n",
    "    \n",
    "    savecost[counter] = cost(W2,W3,W4,b2,b3,b4,x1,x2,y)  #store our cost to observe\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(savecost)\n",
    "plt.show\n",
    "\n",
    "#We are predicting a 'fire' or 'not fire' to predict an x or O on on the map given an\n",
    "#ordered pair\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(0, 1, 200), np.linspace(0, 1, 200))\n",
    "\n",
    "X1Test = np.array(X.ravel())\n",
    "X2Test = np.array(Y.ravel())\n",
    "\n",
    "XTest  = np.stack((X1Test, X2Test), axis = 1)\n",
    "empty  = np.zeros(200*200)\n",
    "\n",
    "\n",
    "for i in np.arange(XTest.shape[0]):\n",
    "\n",
    "    xvec[0,0], xvec[1,0] = XTest[i, 0], XTest[i, 1]\n",
    "\n",
    "\n",
    "    YPredictions = inference(W2, W3, W4, b2, b3, b4, xvec)\n",
    "    YPredictions = np.array(YPredictions[0] >= YPredictions[1])\n",
    "\n",
    "\n",
    "    if YPredictions[0] == True:\n",
    "        empty[i] = 1\n",
    "\n",
    "\n",
    "YPred = empty.reshape((200, 200))\n",
    "plt.figure()\n",
    "plt.contourf(X,Y,YPred,colors=['red','green'])\n",
    "\n",
    "plt.scatter(x1[0:5], x2[0:5], marker='^', lw=5)\n",
    "plt.scatter(x1[5:],  x2[5:], marker='o', lw=5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sys\n",
    "from timeit import default_timer as dt\n",
    "from math import e\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def activate(x,W,b):\n",
    "    '''Defines our activation\n",
    "       function based on the \n",
    "       sigmoid activation.\n",
    "       Takes in the previous neurons\n",
    "       connected outputs x / our \n",
    "       weights W / our bias vector\n",
    "       b'''\n",
    "    return(1/(1+np.exp(-(np.dot(W,x)+b)))) #entire exponent is negative is key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the backbone of our neural network, which is the activation function. Here we utilize the sigmoid function, or $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ which represents a smoothed step function of sorts. Passing through weight matrices, $W$, and bias vectors, $b$, which hold the values to shift and stretch each neuron as it learns through each gradient iteration ultimately enables the firing of proper neurons to accurately make inferences on a desired data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(W2,W3,W4,b2,b3,b4,x1,x2,y):\n",
    "    '''Takes in our weight matrices\n",
    "       and bias vectors and computes\n",
    "       the cost function as defined \n",
    "       in the literature as our final\n",
    "       neurons values, a4 below,\n",
    "       in respect to the true output\n",
    "       squared\n",
    "       x1 - data\n",
    "       x2 - true labels\n",
    "       y - predicted points\n",
    "       Cost is run through Niter #\n",
    "       of times \n",
    "       \n",
    "    '''\n",
    "    costvector = np.zeros((10, 1))\n",
    "    x = np.zeros((2,  1))\n",
    "    for i in np.arange(costvector.shape[0]):\n",
    "        x[0,0], x[1,0] = x1[i], x2[i]\n",
    "        a2 = activate(x,  W2, b2)\n",
    "        a3 = activate(a2, W3, b3)\n",
    "        a4 = activate(a3, W4, b4)\n",
    "        costvector[i] = np.linalg.norm(a4.ravel()-y[:,i], 2)\n",
    "\n",
    "    return np.linalg.norm(costvector, 2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the installment of the cost function, which is used later in the derivation of our $\\delta$ functions for use in forward and backward propogation for the means of updating our weight and bias matrices used to shift and stretch our activation function. For now, our cost function is modeled after the equation $$Cost = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{1}{2}||y(x^{{i}}) - a^{[L]}(x^{{i}})||_{2}^{2}$$\n",
    "\n",
    "where $a^{l}$ runs from $l=2,3,...L$ and represents a neron at layer $l$ for $L$ being our final neuron. $a^{l}$ can be seen as the function describing the output, or the firing or not firing, of neuron $l$ as described by $a^{l} = \\sigma(W^{l}a^{l-1}+b^{l}) \\in \\mathbb{R}^{n_{l}}$ based on the output of the previous neuron and the current weights and biases. Once run through the entire gradient step of the network, the loss is calculated from the activation pattern of our last neuron layer to be compared against our actual values int eh stored $y$ vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(W2, W3, W4, b2, b3, b4, x_vec):\n",
    "    '''Takes in adjusted weights and \n",
    "       biases from cost function that\n",
    "       have run through our network and\n",
    "       return an output layer of \n",
    "       a^[L] = a^4 as the predicted\n",
    "       measure\n",
    "       Takes in processed weights\n",
    "       and biases and 'activates'\n",
    "       through the network using\n",
    "       input xvector data points\n",
    "       and produces a^Lth neuron \n",
    "       for our prediction\n",
    "    '''\n",
    "    a2 = activate(xvec, W2, b2)\n",
    "    a3 = activate(a2,   W3, b3)\n",
    "    a4 = activate(a3,   W4, b4)\n",
    "\n",
    "    return a4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple inference step once our weights and biases are properly trained according to our desired step count and learning rate. This takes in our weights and biases and our x_vec we wish to make predictions on and run them through our activation neurons to determine their grouping on our 2-D plane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([0.1, 0.3, 0.1, 0.6, 0.4, 0.6, 0.5, 0.9, 0.4, 0.7]) #data\n",
    "x2 = np.array([0.1, 0.4, 0.5, 0.9, 0.2, 0.3, 0.6, 0.2, 0.4, 0.6]) \n",
    "\n",
    "y           = np.zeros((2, 10)) #labels (fires or does not fire) \n",
    "y[0:1, 0:5] = np.ones((1,  5))\n",
    "y[0:1, 5: ] = np.zeros((1, 5))\n",
    "y[0:1, 5: ] = np.zeros((1, 5))\n",
    "y[1: , 5: ] = np.ones((1,  5))\n",
    "\n",
    "#Normal randomization used to initialize weight matrices and biases\n",
    "W2 =  npr.uniform(size = (2,2)) #where 1st arg is the current layer size, 2nd is previous arg size\n",
    "W3 =  npr.uniform(size = (3,2)) \n",
    "W4 =  npr.uniform(size = (2,3))\n",
    "\n",
    "b2 = npr.uniform(size = (2,1))\n",
    "b3 = npr.uniform(size = (3,1))\n",
    "b4 = npr.uniform(size = (2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have above an initialization of our data points on our 2-D plane through the $x1$ and $x2$ arrays. From there, the data labels are constructed in our $y$ arrays as either x's or o's as represented by either a 1 or a 0. The standard practice of initializing our weights and biases is done through sampling from a uniform distribution. This gives some sort of starting value for our network to at least begin conducting gradient losses at the beginning of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = .4                                # our learning rate in paper is .05, tried .4 to improve\n",
    "Niter = 100000                          #number of SG iterations\n",
    "\n",
    "savecost = np.zeros((Niter,1))           #save the value of our cost function\n",
    "\n",
    "xvec = np.zeros((2,1))\n",
    "yvec = np.zeros((2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important mathematical topic in this block is the eta variable, which represents our learning rate and allows us to go into the deeper mathematics of stochastic gradient descent and its use in our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
